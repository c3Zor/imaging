{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation: Introduction and Use Cases\n",
    "\n",
    "[VIDEO LINK](https://youtu.be/pLpFynZiiGk)\n",
    "\n",
    "We have discussed the problem statement for semantic segmentation and a few use cases for segmentation in 3D medical imaging:\n",
    "\n",
    "__Longitudinal follow up__: Measuring volumes of things and monitoring how they change over time. These methods are very valuable in, e.g., oncology for tracking slow-growing tumors.\n",
    "Quantifying disease severity: Quite often, it is possible to identify structures in the organism whose size correlates well with the progression of the disease. For example, the size of the hippocampus can tell clinicians about the progression of Alzheimer's disease.\n",
    "\n",
    "__Radiation Therapy Planning__: One of the methods of treating cancer is exposing the tumor to ionizing radiation. In order to target the radiation, an accurate plan has to be created first, and this plan requires careful delineation of all affected organs on a CT scan\n",
    "\n",
    "__Novel Scenarios__: Segmentation is a tedious process that is not quite often done in clinical practice. However, knowing the sizes and extents of the objects holds a lot of promise, especially when combined with other data types. Thus, the field of __radiogenomics__ refers to the study of how the quantitative information obtained from radiological images can be combined with the genetic-molecular features of the organism to discover information not possible before.\n",
    "\n",
    "Now, let’s take a look at some of the methods that are commonly used for building segmentation CNNs.\n",
    "\n",
    "### New Vocabulary\n",
    "__Segmentation__ - the problem of identifying which specific pixels within an image belong to a certain object of interest.\n",
    "\n",
    "## Segmentation Methods\n",
    "\n",
    "[Video Link](https://youtu.be/dKXvycB7d7k)\n",
    "\n",
    "A U-Net architecture has been very successful in analyzing 3D medical images and has spawned multiple offshoots. You will get a chance to get more familiar with it in the exercise that follows, but if you would like to understand the principles better, I recommend that you check out the webpage on U-net created by one of the authors of the original paper, Olaf Ronneberger: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/index.html. You will find the link to the original paper and a few materials explaining how and why this architecture works.\n",
    "\n",
    "Now, let’s move on to the exercise where you will have a chance to train your own segmentation network.\n",
    "\n",
    "### Exercise 2: Segmentation Hands-On\n",
    "This exercise will give you the chance to try out a segmentation network in action. I hope you like it!\n",
    "\n",
    "- Udacity Workspace Note: This workspace is a Jupyter Notebook which has GPU as an option for you to use. At the bottom left of that workspace you will be able to enable/disable GPU. You will only be allocated a set amount of compute hours for the course so while you are just coding you should disable the GPU. When you want to run the training code you can turn it back on to speed the process up. Make sure to also configure PyTorch to use the GPU device.\n",
    "\n",
    "I hope you enjoyed the exercise. You can find the solution for the __Exercise 2: Segmentation Hands On here__[link](https://github.com/udacity/nd320-c3-3d-med-imaging/tree/master/3d-imaging-end-to-end-deep-learning-applications/exercises/2-segmentation-hands-on/solution). If you managed to complete it - you are officially well versed with DICOM, NIFTI, and PyTorch to begin training and designing your own neural networks for medical imaging classification, object detection, and segmentation problems! However, a few important pieces remain. For example, you have noticed that we used simple cross-entropy loss as our cost function. Is this the best cost function possible? Also, after you have your segmentation - how do you efficiently compare it to your ground truth and evaluate performance? We will talk about these things further in this lesson.\n",
    "\n",
    "A couple of final remarks below.\n",
    "\n",
    "Further Resources\n",
    "- If you looked closer at the code for the segmentation network that you have trained in this exercise, you should have noticed the ConvTranspose2D layers and you might be wondering what those are. Remember the upsampling path in the U-net? This is how this upsampling is done. Going into details of those would be straying too far from this course, so if you are curious to learn more about transposed convolutions, how they work, and why, you can read up this blog post: [Up-sampling with Transposed Convolution](https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0) by Naoki Shibuya.\n",
    "- A deep dive into the general approach to building segmentation networks: [Long, Jonathan et al. “Fully convolutional networks for semantic segmentation.” 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015): 3431-3440.](https://arxiv.org/pdf/1605.06211v1.pdf)\n",
    "- [A UNet page by the author, Olaf Ronneberger, with a nice video explaining its principles of operation](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/index.html)\n",
    "- [UNet and overall CNN/DeepLearning content](http://deeplearning.net/tutorial/unet.html)\n",
    "- [Another great explanation of UNet](https://spark-in.me/post/unet-adventures-part-one-getting-acquainted-with-unet)\n",
    "- An overview of radiogenomics: [Bodalal, Z., Trebeschi, S., Nguyen-Kim, T.D.L. et al. Radiogenomics: bridging imaging and genomics. Abdom Radiol 44, 1960–1984 (2019)](https://link.springer.com/article/10.1007/s00261-019-02028-w). https://doi.org/10.1007/s00261-019-02028-w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth for Segmentation\n",
    "[Video Link ](https://youtu.be/bRaBYLk0dpQ)\n",
    "\n",
    "Some of the challenges in creating the ground truth for segmentation have to do with the fact that it is rarely routinely created in clinical practice. Radiation oncology is one of the few fields where segmentation is generated as part of the treatment path, but normally segmentation projects require custom labeling efforts.\n",
    "\n",
    "One of the things to keep in mind when dealing with a labeled (segmented) dataset is that interpretation of radiological images is ambiguous and quite often, two independent clinicians (observers) would not label things in the same way. This phenomenon is called Interobserver Variability and has been studied in the literature.\n",
    "\n",
    "- This is the paper that I have mentioned where the authors present results of measuring the variability between radiation oncologists segmenting structures in the head and neck region: [Mukesh, M et al. “Interobserver variation in clinical target volume and organs at risk segmentation in post-parotidectomy radiotherapy](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3587102/): can segmentation protocols help?.” The British journal of radiology vol. 85,1016 (2012): e530-6. doi:10.1259/bjr/66693547\n",
    "- While I worked on Microsoft’s Project InnerEye we also did our own IOV study for how conformant people are in contouring pelvic anatomy in prostate cancer patients, and included it into our paper which you can read here: [Macomber, M. W., Phillips, M., Tarapov, I., Jena, R., Nori, A., Carter, D., … Nyflot, M. J. (2018). ](https://www.researchgate.net/publication/328485616_Autosegmentation_of_prostate_anatomy_for_radiation_treatment_planning_using_deep_decision_forests_of_radiomic_features)Autosegmentation of prostate anatomy for radiation treatment planning using deep decision forests of radiomic features. Physics in Medicine & Biology, 63(23), 235002. doi: 10.1088/1361-6560/aaeaa4\n",
    "When it comes to tooling for creating ground truth, [3D Slicer](https://www.slicer.org/) is a popular free tool used in the research community, and I will walk you through using it for creation and review of segmentation labels in the next lessons. [MITK](http://www.mitk.org/wiki/MITK) is another one. However, many medical imaging startups and larger companies use tools of their own.\n",
    "\n",
    "## Evaluating Performance as a Data Scientist\n",
    "\n",
    "[video link](https://youtu.be/5IaZNkLiGKY)\n",
    "\n",
    "We have discussed four metrics that you can use to evaluate the performance of your segmentation models. As usual, a great explanation of these can also be found on Wikipedia which I’m linking here if you are looking for additional details:\n",
    "\n",
    "- [Sensitivity and Specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n",
    "- [Dice Similarity Coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient)\n",
    "- [Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index)\n",
    "- [Hausdorff Distance](https://en.wikipedia.org/wiki/Hausdorff_distance)\n",
    "\n",
    "Note these metrics as they are very handy as you are publishing your model’s validation reports, but also they could be used to construct more elaborate cost functions. We will take a closer look at how these metrics work, but for now, let’s see how clinicians think of performance.\n",
    "\n",
    "## Evaluating Performance as a Clinician\n",
    "Below, Mazen will present a clinician’s perspective on assessing the performance of assistive systems in general, not only segmentation models. It is important to understand this perspective for a data scientist so that you can speak with clinicians in common terms.\n",
    "\n",
    "[Video link](https://youtu.be/18c8fjD-EBQ)\n",
    "\n",
    "Note how I am talking about performance in a different sense. As a clinician, I need to make decisions about the presence of conditions or selecting the course of treatment. For that, clinicians operate in terms of Likelihood Ratios.\n",
    "\n",
    "The likelihood ratio for a diagnostic test result can be calculated if the predictive characteristics (sensitivity and specificity) of that test are known. Likelihood ratios are known for common diagnostic tests performed by humans (e.g., correctly identifying viral pneumonia from chest CT scans). This means that for example, your ML segmentation algorithm may be measuring the volume of a specific anomaly in the lung very accurately, but this measurement, while important to quantify the degree of lung involvement by some disease state, may be not specific at all for predicting whether that state is due to a viral pneumonia (e.g., presence of such anomalies could mean viral pneumonia, bacterial pneumonia or non-infectious causes like hemorrhage or edema). Thus, your algorithm with high Dice scores may end up being not very useful to solve a clinical task if the goal is a specific diagnosis.\n",
    "\n",
    "## Exercise 3: Measuring Performance\n",
    "Now let’s get technical for a bit and take a crack at implementing algorithms for computing some of the performance metrics we have discussed. In the workspace below, you will find a Python file with instructions and a pair of NIFTI binary segmentation masks to compare.\n",
    "\n",
    "Congratulations on completing the exercise! We hope you enjoyed it. If you are feeling adventurous, you can do an optional activity: go back to Exercise 2 from this lesson and try to replace the cross-entropy loss function that we have used to train our UNet with a metric you have just implemented. See how your performance and time to train changes, especially if you add more slices into your “training set”.\n",
    "\n",
    "If you would like to explore the topic further, here is a paper with an excellent overview of various metrics for evaluation of 3D medical image segmentation:[ Taha AA, Hanbury A. Metrics for evaluating 3D medical image segmentation: analysis, selection, and tool. BMC Med Imaging. 2015;15:29. Published 2015 Aug 12. doi:10.1186/s12880-015-0068-x](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4533825/)\n",
    "\n",
    "You can find the solution for the __Exercise 3: Measuring Performance__ [here](https://github.com/udacity/nd320-c3-3d-med-imaging/tree/master/3d-imaging-end-to-end-deep-learning-applications/exercises/3-performance-metrics/solution). Note how the Dice score and statistical accuracy measures have quite elegant expression in Python code.\n",
    "\n",
    "## Machine Learning Methods Recap and Looking Beyond\n",
    "\n",
    "[Video Link](https://youtu.be/rOizCQRtcNk)\n",
    "Congratulations on completing our lesson on practical machine learning methods for 3D medical imaging analysis! The skills that you have learned through watching videos and doing exercises will help you in the final project where you will build your own AI system using a U-net implementation, and apply it to DICOM datasets.\n",
    "\n",
    "In this lesson, we have covered the following:\n",
    "\n",
    "- A quick refresher on how convolutional neural networks operate and a took a closer look at the different types of convolutions that underlie the operation of these networks.\n",
    "- Ways to approach segmentation and classification problems for 3D medical imaging\n",
    "- We did an exercise where we trained our own segmentation network on a medical imaging dataset\n",
    "- Technical methods for evaluating performance of CNNs for 3D medical image analysis, and talked about the clinical aspect of evaluating performance.\n",
    "Before we are ready to implement the full-scale AI solution in the final project, there is one final set of concepts that I want you to get familiar with - how to integrate such algorithms into real-world systems, and what these real-world systems look like. This would be the topic of our next lesson.\n",
    "\n",
    "## Further Resources\n",
    "## More problems\n",
    "\n",
    "As mentioned in my closing remarks, machine learning problems in 3D medical imaging do not boil down to only classification and segmentation. The two problems we’ve looked at here help you understand the principles, but there is so much more you can do. Here are some pointers for some amazing things people do with deep neural networks in 3D medical imaging:\n",
    "\n",
    "- [Using deep learning to increase the resolution of low-res scans: Chaudhari AS, Fang Z, Kogan F, et al. Super-resolution musculoskeletal MRI using deep learning. Magn Reson Med. 2018;80(5):2139–2154. doi:10.1002/mrm.27178](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6107420/)\n",
    "- [GANs for synthetic MRI: Frid-Adar, M., Diamant, I., Klang, E., Amitai, M., Goldberger, J., & Greenspan, H. (2018). GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification. Neurocomputing, 321, 321–331. doi: 10.1016/j.neucom.2018.09.013](https://arxiv.org/pdf/1803.01229.pdf)\n",
    "- [A survey of deep learning methods for medical image registration: Haskins, G., Kruger, U. & Yan, P. Deep learning in medical image registration: a survey. Machine Vision and Applications 31, 8 (2020). https://doi.org/10.1007/s00138-020-01060-x](https://arxiv.org/abs/1903.02026)\n",
    "- [Overview of opportunities for deep learning on MRIs: Lundervold, A. S., & Lundervold, A. (2019). An overview of deep learning in medical imaging focusing on MRI. Zeitschrift Für Medizinische Physik, 29(2), 102–127. doi: 10.1016/j.zemedi.2018.11.002](https://www.sciencedirect.com/science/article/pii/S0939388918301181)\n",
    "\n",
    "## Tools and libraries\n",
    "We tried to minimize the dependency on external libraries and focus on understanding some key concepts. At the same time, there are many tools that the community has developed, which will help you get moving faster with the tasks typical for medical imaging ML workflows.\n",
    "\n",
    "A few tools/repos worthy of attention are:\n",
    "\n",
    "- Fast.ai - python library for medical image analysis, with focus on ML: https://dev.fast.ai/medical.imaging\n",
    "- MedPy - a library for medical image processing with lots of various higher-order processing methods: https://pypi.org/project/MedPy/\n",
    "- Deepmedic, a library for 3D CNNs for medical image segmentation: https://github.com/deepmedic/deepmedic\n",
    "- Work by the German Cancer Research Institute:\n",
    "https://github.com/MIC-DKFZ/trixi - a boilerplate for machine learning experiment\n",
    "https://github.com/MIC-DKFZ/batchgenerators - tooling for data augmentation\n",
    "\n",
    "A publication about a project dedicated to large-scale medical imaging ML model evaluation which includes a comprehensive overview of annotation tools and related problems (including inter-observer variability): https://link.springer.com/chapter/10.1007%2F978-3-319-49644-3_4\n",
    "\n",
    "### Books\n",
    "Some resources readily available online for free will help you grasp the basic concepts of computer vision and overall machine learning.\n",
    "\n",
    "https://d2l.ai/ - deep learning with a special section on computer vision by Alexander Smola et al. Alexander has a strong history of publications on machine learning algorithms and statistical analysis and is presently serving as a director for machine learning at Amazon Web Services in Palo Alto, CA\n",
    "http://www.mbmlbook.com/ - a book on general concepts of machine learning by Christopher Bishop et al. Christopher has a distinguished career as a machine learning scientist and presently is in charge of Microsoft Research lab in Cambridge, UK, where I had the honor to work on project [InnerEye](https://www.microsoft.com/en-us/research/project/medical-image-analysis/) for several years.\n",
    "\n",
    "## More notable papers\n",
    "If you’re curious about segmentation space specifically, you may appreciate a foray into non-ML-based methods for segmentation. A couple of papers that can provide an introduction into that space are:\n",
    "- [Boykov, Y., & Jolly, M.-P. (2000). Interactive Organ Segmentation Using Graph Cuts. Medical Image Computing and Computer-Assisted Intervention – MICCAI 2000 Lecture Notes in Computer Science, 276–286. doi: 10.1007/978-3-540-40899-4_28](https://cs.uwaterloo.ca/~yboykov/Papers/miccai00.pdf)\n",
    "- [Probabilistic Graphical Models for Medical Image Segmentation](https://www.researchgate.net/publication/280664591_Probabilistic_Graphical_Models_for_Medical_Image_Segmentation)\n",
    "This GitHub repo provides an excellent overview of CNN-based seg methods for general image domain: https://github.com/mrgloom/awesome-semantic-segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "- __Classification__ - the problem of determining which one of several classes an image belongs to.\n",
    "- __Object Detection__ - the problem of finding a (typically rectangular) region within an image that matches with one of several classes of interest.\n",
    "- __Segmentation__ - the problem of identifying which specific pixels within an image belong to a certain object of interest.\n",
    "- __2D Convolution__ - an approach to feature extraction where a convolutional filter is applied to a single 2D image.\n",
    "- __2.5D Convolution__ - an approach to feature extraction where 2D convolutions are applied independently to areas around each voxel (either in neighboring planes or in orthogonal planes) and their results are summed up to form a 2D feature map. Such an approach leverages some 3-dimensional information.\n",
    "- __3D Convolution__ - an approach to feature extraction where the convolutional kernel is 3 dimensional and thus combines information from all 3 dimensions into the feature map.\n",
    "- __Longitudinal follow up__ - radiological analysis method that involves monitoring how things change over time. These methods are very valuable in, e.g., oncology for tracking slow-growing tumors.\n",
    "- __Radiation Therapy__ - one of the methods of treating cancer where the tumor is exposed to ionizing radiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
