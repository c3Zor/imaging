{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "# DICOM Dataset EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will discuss some of the methods that could be applied in dataset analysis, when you are dealing with large multitude of 3D volumes. A lot of the same principles could be applied here as were used with individual volume EDA.\n",
    "\n",
    "In this case we will look at a collection of images and try to figure out what we are looking at. We will look at some of the techniques that might help us collect relevant meta information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy.ma as ma\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load all series metadata, but not pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidDicomError",
     "evalue": "File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidDicomError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5e9004ccf6fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"data/data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m series = np.array([[(os.path.join(dp, f), pydicom.dcmread(os.path.join(dp, f), stop_before_pixels = True)) for f in files]\n\u001b[0;32m----> 3\u001b[0;31m                    for dp,_,files in os.walk(path) if len(files) != 0])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5e9004ccf6fa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"data/data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m series = np.array([[(os.path.join(dp, f), pydicom.dcmread(os.path.join(dp, f), stop_before_pixels = True)) for f in files]\n\u001b[0;32m----> 3\u001b[0;31m                    for dp,_,files in os.walk(path) if len(files) != 0])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5e9004ccf6fa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"data/data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m series = np.array([[(os.path.join(dp, f), pydicom.dcmread(os.path.join(dp, f), stop_before_pixels = True)) for f in files]\n\u001b[0m\u001b[1;32m      3\u001b[0m                    for dp,_,files in os.walk(path) if len(files) != 0])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdcmread\u001b[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         dataset = read_partial(fp, stop_when, defer_size=defer_size,\n\u001b[0;32m--> 871\u001b[0;31m                                force=force, specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcaller_owns_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;31m# Read preamble (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m     \u001b[0mpreamble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_preamble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Read any File Meta Information group (0002,eeee) elements (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mfile_meta_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_file_meta_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_preamble\u001b[0;34m(fp, force)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"DICM\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         raise InvalidDicomError(\"File is missing DICOM File Meta Information \"\n\u001b[0m\u001b[1;32m    622\u001b[0m                                 \u001b[0;34m\"header or the 'DICM' prefix is missing from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                                 \"the header. Use force=True to force reading.\")\n",
      "\u001b[0;31mInvalidDicomError\u001b[0m: File is missing DICOM File Meta Information header or the 'DICM' prefix is missing from the header. Use force=True to force reading."
     ]
    }
   ],
   "source": [
    "path = r\"data/data\"\n",
    "series = np.array([[(os.path.join(dp, f), pydicom.dcmread(os.path.join(dp, f), stop_before_pixels = True)) for f in files]\n",
    "                   for dp,_,files in os.walk(path) if len(files) != 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print a few, see what we've got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series[0][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Looks like we have MR data*  \n",
    "*Looks like we can rely on patient IDs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many total files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [f for l in series for f in l]\n",
    "len(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = np.unique([inst[1].PatientID for inst in instances])\n",
    "len(patient_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Great - no errors hence all instances have the PatientID tag, and looks like we can rely on it*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many total series (i.e. 3D volumes)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the relationship between patients, studies and series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many studies?\n",
    "\n",
    "studies = {}\n",
    "\n",
    "for s in series:\n",
    "    studies.setdefault(s[0][1].StudyInstanceUID, []).append(s)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(studies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many studies per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len([st for st in studies.values() if st[0][0][1].PatientID == p]) for p in patient_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nice, all even. Let's look at directory on the file system.*  \n",
    "*Looks like 2 points in time per patient*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many series per study\n",
    "\n",
    "series_per_study = [(len(sr), sr[0][0][1].PatientID) for sr in studies.values()]\n",
    "series_per_study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick glimpse at that outlier on the file system. \n",
    "\n",
    "- seems like it's missing some sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, how many images per series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_per_series = [len(s) for s in series]\n",
    "print(img_per_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nice, no outliers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at spacing and in-plane resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "spc = {}\n",
    "thck = {}\n",
    "\n",
    "for sr in series:\n",
    "    dcm = sr[0][1]\n",
    "    key = str(dcm.PixelSpacing)\n",
    "    spc.setdefault(key, [])\n",
    "    spc[key].append((dcm.PatientID, dcm.StudyDescription, dcm.StudyDate, dcm.SeriesDescription))\n",
    "    \n",
    "    key = str((dcm.Rows, dcm.Columns))\n",
    "    res.setdefault(key, [])\n",
    "    res[key].append((dcm.PatientID, dcm.StudyDescription, dcm.StudyDate, dcm.SeriesDescription))\n",
    "    \n",
    "    key = str(dcm.SliceThickness)\n",
    "    thck.setdefault(key, [])\n",
    "    thck[key].append((dcm.PatientID, dcm.StudyDescription, dcm.StudyDate, dcm.SeriesDescription))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at slice thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thck.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Great, all consistent*\n",
    "\n",
    "Let's look at pixel spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not very consistent, let's try to see what is going on*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*So looks like there is a slight discrepancy among T1/T2 series. Note to self - make sure to resample if I'm using them.  \n",
    "Also, seems that some sequences have tighter pixels than others. If I'm using those, need to make sure resampling is meaningful*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at in-plane resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not a lot of variety, but clearly some seq types are high-res, need to see what's up*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize some of those images and see if the series align with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to see how images from same series stack w each other. We might want to use multiple\n",
    "# input channels for our problem\n",
    "\n",
    "# Remember, though, that we don't have the pixel data? Let's load it properly:\n",
    "\n",
    "seq1 = r\"PGBM-003/10-17-1995-MR RCBV SEQUENCE-57198/34911-T1prereg-46949\"\n",
    "t1_slices = [pydicom.dcmread(os.path.join(path, seq1, f)) for f in os.listdir(os.path.join(path, seq1))]\n",
    "t1_slices.sort(key = lambda inst: int(inst.ImagePositionPatient[2]))\n",
    "\n",
    "seq2 = r\"PGBM-003/10-17-1995-MR RCBV SEQUENCE-57198/36471-FLAIRreg-02052\"\n",
    "flair_slices = [pydicom.dcmread(os.path.join(path, seq2, f)) for f in os.listdir(os.path.join(path, seq2))]\n",
    "flair_slices.sort(key = lambda inst: int(inst.ImagePositionPatient[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t1_slices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flair_slices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.stack([s.pixel_array for s in t1_slices])\n",
    "flair = np.stack([s.pixel_array for s in flair_slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ipp.ImagePositionPatient for ipp in t1_slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[ipp.ImagePositionPatient for ipp in flair_slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([ipp.ImageOrientationPatient for ipp in t1_slices]) - np.array([ipp.ImageOrientationPatient for ipp in flair_slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow((flair+1.0*t1)[9,:,:], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((0.0*flair+t1)[9,:,:], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could visualize a few more series, and probably run some code to ensure IPP and IOP alignment across all of the dataset. We could maybe load this data in Slicer to get a feel of what we are dealing with, and then start looking at the ground truth and photometrics. \n",
    "\n",
    "However, by going through these simple steps, we already learned the following about our dataset:\n",
    "\n",
    "* We are dealing with MR images\n",
    "* We have data from 4 patients\n",
    "* Each patient has 2 studies representing 2 time points\n",
    "* Each study has between 8 and 10 series, 76 series altogether\n",
    "* In total we have 1794 slices\n",
    "* We have varying pixel spacing, even within same sequence types\n",
    "* We have consistent slice thickness (5mm)\n",
    "* We have low-res slices (older ones) and higher-res slices (newer ones)\n",
    "* Our volumes seem to all be registered together and thus it is safe to just align them. I.e. they could be passed as multi-channel data into our ML algorithms\n",
    "\n",
    "That is a lot! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
